<!DOCTYPE html>
<html lang="en" dir="ltr">
<head><script src="/go-crawler/docs/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=go-crawler/docs/livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="
  Options
  #

Options refer to items that can be configured in the code.

  Spider Options
  #


WithName: Set a unique name for the spider.
WithHost: Set the host for filtering based on the host or to support robots.txt.
WithPlatforms: Set the browser platforms.
WithBrowsers: Set the browsers.
WithFilter: Set the filter.
WithDownloader: Set the downloader.
WithExporter: Set the exporter.
WithMiddleware: Set middleware components.
WithStatsMiddleware: Set the statistics middleware to record and monitor the performance and runtime of the
spider.
WithDumpMiddleware: Set the dump middleware to print requests or responses.
WithProxyMiddleware: Set the proxy middleware to use proxy servers for crawling.
WithRobotsTxtMiddleware: Set the middleware to enable robots.txt support, ensuring compliance with websites&#39;
robots.txt rules.
WithFilterMiddleware: Set the filter middleware to filter processed requests.
WithFileMiddleware: Set the file middleware to handle file download requests.
WithImageMiddleware: Set the image middleware to handle image download requests.
WithHttpMiddleware: Set the HTTP middleware.
WithRetryMiddleware: Set the retry middleware for automatic retries in case of request failures.
WithUrlMiddleware: Set the URL middleware.
WithReferrerMiddleware: Set the referrer middleware to automatically set the Referrer header for requests.
WithCookieMiddleware: Set the cookie middleware to handle cookies in requests and responses, automatically
preserving cookies for subsequent requests.
WithRedirectMiddleware: Set the redirect middleware to automatically handle request redirections, following the
redirect links to obtain the final response.
WithChromeMiddleware: Set the Chrome middleware to simulate the Chrome browser.
WithHttpAuthMiddleware: Enable the HTTP authentication middleware to handle websites that require
authentication.
WithCompressMiddleware: Set the compress middleware to handle compression in requests and responses. When the
crawler sends requests or receives responses, this middleware can automatically handle compression algorithms,
decompressing the content of requests or responses.
WithDecodeMiddleware: Set the decode middleware to handle decoding operations in requests and responses. This
middleware can handle encoding content in requests or responses.
WithDeviceMiddleware: Enable the device simulation middleware.
WithCustomMiddleware: Set the custom middleware, allowing users to define their own middleware components.
WithRecordErrorMiddleware Set up error logging middleware, request and parsing will be logged if there is an error
WithPipeline: Set the Pipeline to process the crawled data and perform subsequent operations.
WithDumpPipeline: Set the dump pipeline to print data to be saved.
WithFilePipeline: Set the file pipeline to handle crawled file data and save files to a specified location.
WithImagePipeline: Set the image pipeline to handle crawled image data and save images to a specified location.
WithFilterPipeline: Set the filter pipeline to filter crawled data.
WithCsvPipeline: Set the CSV data processing pipeline to save crawled data in CSV format.
WithJsonLinesPipeline: Set the JSON Lines data processing pipeline to save crawled data in JSON Lines format.
WithMongoPipeline: Set the MongoDB data processing pipeline to save crawled data to a MongoDB database.
WithSqlitePipeline: Set the Sqlite data processing pipeline to save crawled data to a Sqlite database.
WithMysqlPipeline: Set the MySQL data processing pipeline to save crawled data to a MySQL database.
WithKafkaPipeline: Set the Kafka data processing pipeline to send crawled data to a Kafka message queue.
WithCustomPipeline: Set the custom data processing pipeline.
WithRetryMaxTimes: Set the maximum number of retries for requests.
WithRedirectMaxTimes Set the maximum number of redirect for requests.
WithTimeout: Set the timeout for requests.
WithInterval: Set the interval between requests.
WithOkHttpCodes: Set the normal HTTP status codes.


  Crawler Options
  #


WithLogger: Set the logger.
WithMockServerRoutes Configure development service routes, including built-in or custom ones. You don&rsquo;t need to
set mock_server.enable: true to enable the mock Server.
WithItemDelay sets the data saving interval.
WithItemConcurrency sets the data saving parallelism.
WithCDP initial browser.
">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/go-crawler/docs/docs/usage/options/">
  <meta property="og:site_name" content="Go Crawler">
  <meta property="og:title" content="Options">
  <meta property="og:description" content="Options # Options refer to items that can be configured in the code.
Spider Options # WithName: Set a unique name for the spider. WithHost: Set the host for filtering based on the host or to support robots.txt. WithPlatforms: Set the browser platforms. WithBrowsers: Set the browsers. WithFilter: Set the filter. WithDownloader: Set the downloader. WithExporter: Set the exporter. WithMiddleware: Set middleware components. WithStatsMiddleware: Set the statistics middleware to record and monitor the performance and runtime of the spider. WithDumpMiddleware: Set the dump middleware to print requests or responses. WithProxyMiddleware: Set the proxy middleware to use proxy servers for crawling. WithRobotsTxtMiddleware: Set the middleware to enable robots.txt support, ensuring compliance with websites&#39; robots.txt rules. WithFilterMiddleware: Set the filter middleware to filter processed requests. WithFileMiddleware: Set the file middleware to handle file download requests. WithImageMiddleware: Set the image middleware to handle image download requests. WithHttpMiddleware: Set the HTTP middleware. WithRetryMiddleware: Set the retry middleware for automatic retries in case of request failures. WithUrlMiddleware: Set the URL middleware. WithReferrerMiddleware: Set the referrer middleware to automatically set the Referrer header for requests. WithCookieMiddleware: Set the cookie middleware to handle cookies in requests and responses, automatically preserving cookies for subsequent requests. WithRedirectMiddleware: Set the redirect middleware to automatically handle request redirections, following the redirect links to obtain the final response. WithChromeMiddleware: Set the Chrome middleware to simulate the Chrome browser. WithHttpAuthMiddleware: Enable the HTTP authentication middleware to handle websites that require authentication. WithCompressMiddleware: Set the compress middleware to handle compression in requests and responses. When the crawler sends requests or receives responses, this middleware can automatically handle compression algorithms, decompressing the content of requests or responses. WithDecodeMiddleware: Set the decode middleware to handle decoding operations in requests and responses. This middleware can handle encoding content in requests or responses. WithDeviceMiddleware: Enable the device simulation middleware. WithCustomMiddleware: Set the custom middleware, allowing users to define their own middleware components. WithRecordErrorMiddleware Set up error logging middleware, request and parsing will be logged if there is an error WithPipeline: Set the Pipeline to process the crawled data and perform subsequent operations. WithDumpPipeline: Set the dump pipeline to print data to be saved. WithFilePipeline: Set the file pipeline to handle crawled file data and save files to a specified location. WithImagePipeline: Set the image pipeline to handle crawled image data and save images to a specified location. WithFilterPipeline: Set the filter pipeline to filter crawled data. WithCsvPipeline: Set the CSV data processing pipeline to save crawled data in CSV format. WithJsonLinesPipeline: Set the JSON Lines data processing pipeline to save crawled data in JSON Lines format. WithMongoPipeline: Set the MongoDB data processing pipeline to save crawled data to a MongoDB database. WithSqlitePipeline: Set the Sqlite data processing pipeline to save crawled data to a Sqlite database. WithMysqlPipeline: Set the MySQL data processing pipeline to save crawled data to a MySQL database. WithKafkaPipeline: Set the Kafka data processing pipeline to send crawled data to a Kafka message queue. WithCustomPipeline: Set the custom data processing pipeline. WithRetryMaxTimes: Set the maximum number of retries for requests. WithRedirectMaxTimes Set the maximum number of redirect for requests. WithTimeout: Set the timeout for requests. WithInterval: Set the interval between requests. WithOkHttpCodes: Set the normal HTTP status codes. Crawler Options # WithLogger: Set the logger. WithMockServerRoutes Configure development service routes, including built-in or custom ones. You don’t need to set mock_server.enable: true to enable the mock Server. WithItemDelay sets the data saving interval. WithItemConcurrency sets the data saving parallelism. WithCDP initial browser.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="website">
<title>Options | Go Crawler</title>
<link rel="icon" href="/go-crawler/docs/favicon.png" >
<link rel="manifest" href="/go-crawler/docs/manifest.json">
<link rel="canonical" href="http://localhost:1313/go-crawler/docs/docs/usage/options/">
  <link rel="alternate" hreflang="zh" href="http://localhost:1313/go-crawler/docs/zh/docs/usage/options/" title="选项">
<link rel="stylesheet" href="/go-crawler/docs/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css" integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin="anonymous">
  <script defer src="/go-crawler/docs/fuse.min.js"></script>
  <script defer src="/go-crawler/docs/en.search.min.aca0e7cbd28cf468b1858107f51a7c5782bc901eb4c7187c1f39b137abb168bf.js" integrity="sha256-rKDny9KM9GixhYEH9Rp8V4K8kB60xxh8HzmxN6uxaL8=" crossorigin="anonymous"></script>

  <script defer src="/go-crawler/docs/sw.min.8f5f8d39ce37f8232a7f0317a8026655f90799b045d8556ccd203097bfcc6627.js" integrity="sha256-j1&#43;NOc43&#43;CMqfwMXqAJmVfkHmbBF2FVszSAwl7/MZic=" crossorigin="anonymous"></script>
<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/go-crawler/docs/docs/usage/options/index.xml" title="Go Crawler" />
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/go-crawler/docs/"><span>Go Crawler</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>



  



  
    
  


  


<ul class="book-languages">
  <li>
    <input type="checkbox" id="languages" class="toggle" />
    <label for="languages" class="flex justify-between">
      <a role="button" class="flex align-center">
        <img src="/go-crawler/docs/svg/translate.svg" class="book-icon" alt="Languages" />
        English
      </a>
    </label>

    <ul>
      
      <li>
        <a href="/go-crawler/docs/zh/docs/usage/options/">
          Chinese
        </a>
      </li>
      
    </ul>
  </li>
</ul>












  



  
  <ul>
    
      
        <li>
          
  
  

  
    <span>Docs</span>
  

          
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/go-crawler/docs/docs/introduction/" class="">Introduction</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/" class="">Usage</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/architecture/" class="">Basic Architecture</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/options/" class="active">Options</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/item/" class="">Item</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/tools/" class="">Tools</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/middleware/" class="">Middleware</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/pipeline/" class="">Pipeline</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/request/" class="">Request</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/response/" class="">Response</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/signals/" class="">Signals</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/proxy/" class="">Proxy</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/download/" class="">Media Downloads</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/mock_server/" class="">Mock Server</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/configuration/" class="">Configuration</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/startup/" class="">Startup</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/parse/" class="">Web Page Parsing Based on Field Tags</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/question/" class="">Q &amp; A</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/usage/example/" class="">Example Code</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/go-crawler/docs/docs/admin/" class="">Admin</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/admin/api/" class="">Api</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/docs/admin/ui/" class="">UI</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>Todo</span>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>










  
<ul>
  
  <li>
    <a href="https://github.com/lizongying/go-crawler"  target="_blank" rel="noopener">
        Github
      </a>
  </li>
  
  <li>
    <a href="https://lizongying.github.io/go-crawler/"  target="_blank" rel="noopener">
        Go Crawler Admin
      </a>
  </li>
  
</ul>






</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/go-crawler/docs/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Options</h3>

  <label for="toc-control">
    
    <img src="/go-crawler/docs/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#options">Options</a>
          <ul>
            <li><a href="#spider-options">Spider Options</a></li>
            <li><a href="#crawler-options">Crawler Options</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h2 id="options">
  Options
  <a class="anchor" href="#options">#</a>
</h2>
<p>Options refer to items that can be configured in the code.</p>
<h3 id="spider-options">
  Spider Options
  <a class="anchor" href="#spider-options">#</a>
</h3>
<ul>
<li><code>WithName</code>: Set a unique name for the spider.</li>
<li><code>WithHost</code>: Set the host for filtering based on the host or to support robots.txt.</li>
<li><code>WithPlatforms</code>: Set the browser platforms.</li>
<li><code>WithBrowsers</code>: Set the browsers.</li>
<li><code>WithFilter</code>: Set the filter.</li>
<li><code>WithDownloader</code>: Set the downloader.</li>
<li><code>WithExporter</code>: Set the exporter.</li>
<li><code>WithMiddleware</code>: Set middleware components.</li>
<li><code>WithStatsMiddleware</code>: Set the statistics middleware to record and monitor the performance and runtime of the
spider.</li>
<li><code>WithDumpMiddleware</code>: Set the dump middleware to print requests or responses.</li>
<li><code>WithProxyMiddleware</code>: Set the proxy middleware to use proxy servers for crawling.</li>
<li><code>WithRobotsTxtMiddleware</code>: Set the middleware to enable robots.txt support, ensuring compliance with websites'
robots.txt rules.</li>
<li><code>WithFilterMiddleware</code>: Set the filter middleware to filter processed requests.</li>
<li><code>WithFileMiddleware</code>: Set the file middleware to handle file download requests.</li>
<li><code>WithImageMiddleware</code>: Set the image middleware to handle image download requests.</li>
<li><code>WithHttpMiddleware</code>: Set the HTTP middleware.</li>
<li><code>WithRetryMiddleware</code>: Set the retry middleware for automatic retries in case of request failures.</li>
<li><code>WithUrlMiddleware</code>: Set the URL middleware.</li>
<li><code>WithReferrerMiddleware</code>: Set the referrer middleware to automatically set the Referrer header for requests.</li>
<li><code>WithCookieMiddleware</code>: Set the cookie middleware to handle cookies in requests and responses, automatically
preserving cookies for subsequent requests.</li>
<li><code>WithRedirectMiddleware</code>: Set the redirect middleware to automatically handle request redirections, following the
redirect links to obtain the final response.</li>
<li><code>WithChromeMiddleware</code>: Set the Chrome middleware to simulate the Chrome browser.</li>
<li><code>WithHttpAuthMiddleware</code>: Enable the HTTP authentication middleware to handle websites that require
authentication.</li>
<li><code>WithCompressMiddleware</code>: Set the compress middleware to handle compression in requests and responses. When the
crawler sends requests or receives responses, this middleware can automatically handle compression algorithms,
decompressing the content of requests or responses.</li>
<li><code>WithDecodeMiddleware</code>: Set the decode middleware to handle decoding operations in requests and responses. This
middleware can handle encoding content in requests or responses.</li>
<li><code>WithDeviceMiddleware</code>: Enable the device simulation middleware.</li>
<li><code>WithCustomMiddleware</code>: Set the custom middleware, allowing users to define their own middleware components.</li>
<li><code>WithRecordErrorMiddleware</code> Set up error logging middleware, request and parsing will be logged if there is an error</li>
<li><code>WithPipeline</code>: Set the Pipeline to process the crawled data and perform subsequent operations.</li>
<li><code>WithDumpPipeline</code>: Set the dump pipeline to print data to be saved.</li>
<li><code>WithFilePipeline</code>: Set the file pipeline to handle crawled file data and save files to a specified location.</li>
<li><code>WithImagePipeline</code>: Set the image pipeline to handle crawled image data and save images to a specified location.</li>
<li><code>WithFilterPipeline</code>: Set the filter pipeline to filter crawled data.</li>
<li><code>WithCsvPipeline</code>: Set the CSV data processing pipeline to save crawled data in CSV format.</li>
<li><code>WithJsonLinesPipeline</code>: Set the JSON Lines data processing pipeline to save crawled data in JSON Lines format.</li>
<li><code>WithMongoPipeline</code>: Set the MongoDB data processing pipeline to save crawled data to a MongoDB database.</li>
<li><code>WithSqlitePipeline</code>: Set the Sqlite data processing pipeline to save crawled data to a Sqlite database.</li>
<li><code>WithMysqlPipeline</code>: Set the MySQL data processing pipeline to save crawled data to a MySQL database.</li>
<li><code>WithKafkaPipeline</code>: Set the Kafka data processing pipeline to send crawled data to a Kafka message queue.</li>
<li><code>WithCustomPipeline</code>: Set the custom data processing pipeline.</li>
<li><code>WithRetryMaxTimes</code>: Set the maximum number of retries for requests.</li>
<li><code>WithRedirectMaxTimes</code> Set the maximum number of redirect for requests.</li>
<li><code>WithTimeout</code>: Set the timeout for requests.</li>
<li><code>WithInterval</code>: Set the interval between requests.</li>
<li><code>WithOkHttpCodes</code>: Set the normal HTTP status codes.</li>
</ul>
<h3 id="crawler-options">
  Crawler Options
  <a class="anchor" href="#crawler-options">#</a>
</h3>
<ul>
<li><code>WithLogger</code>: Set the logger.</li>
<li><code>WithMockServerRoutes</code> Configure development service routes, including built-in or custom ones. You don&rsquo;t need to
set <code>mock_server.enable: true</code> to enable the mock Server.</li>
<li><code>WithItemDelay</code> sets the data saving interval.</li>
<li><code>WithItemConcurrency</code> sets the data saving parallelism.</li>
<li><code>WithCDP</code> initial browser.</li>
</ul>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">


  <div><a class="flex align-center" href="https://github.com/lizongying/go-crawler/commit/7c81a24f40a46a6ade140981458f412ccd6d0c98" title='Last modified by Li ZongYing | November 27, 2023' target="_blank" rel="noopener">
      <img src="/go-crawler/docs/svg/calendar.svg" class="book-icon" alt="" />
      <span>November 27, 2023</span>
    </a>
  </div>



  <div>
    <a class="flex align-center" href="https://github.com/lizongying/go-crawler/edit/development/docs/content/en/docs/usage/options/_index.md" target="_blank" rel="noopener">
      <img src="/go-crawler/docs/svg/edit.svg" class="book-icon" alt="" />
      <span>Edit this page</span>
    </a>
  </div>


</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#options">Options</a>
          <ul>
            <li><a href="#spider-options">Spider Options</a></li>
            <li><a href="#crawler-options">Crawler Options</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












