<!DOCTYPE html>
<html lang="zh" dir="ltr">
<head><script src="/go-crawler/docs/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=go-crawler/docs/livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="
  选项
  #

选项是指可以在代码中配置的条目

  Spider选项
  #


WithName 设置唯一名称。
WithHost 设置host，用于基于host的过滤或robot.txt的支持。
WithPlatforms 设置浏览器平台。
WithBrowsers 设置浏览器。
WithFilter 设置过滤器。
WithDownloader 设置下载器。
WithExporter 设置导出器。
WithMiddleware 设置中间件。
WithStatsMiddleware 设置统计中间件，用于记录和统计爬虫的性能和运行情况。
WithDumpMiddleware 设置打印中间件，打印request或者response。
WithProxyMiddleware 设置代理中间件，用于使用代理服务器进行爬取。
WithRobotsTxtMiddleware 设置开启robots.txt支持中间件，用于遵守网站的 robots.txt 规则。
WithFilterMiddleware 设置过滤器中间件，用于过滤已处理的请求。
WithFileMiddleware 设置文件中间件，用于处理文件下载请求。
WithImageMiddleware 设置图像中间件，用于处理图像下载请求。
WithHttpMiddleware 设置 HTTP 中间件。
WithRetryMiddleware 设置重试中间件，用于在请求失败时进行自动重试。
WithUrlMiddleware 设置 URL 中间件。
WithReferrerMiddleware 设置 Referrer 中间件，用于自动设置请求的 Referrer 头。
WithCookieMiddleware 设置 Cookie 中间件，用于处理请求和响应中的 Cookie，自动在接下来的请求设置之前的 Cookie。
WithRedirectMiddleware 设置重定向中间件，用于自动处理请求的重定向，跟随重定向链接并获取最终响应。
WithChromeMiddleware 设置 Chrome 中间件，用于模拟 Chrome 浏览器。
WithHttpAuthMiddleware 设置开启HTTP认证中间件，用于处理需要认证的网站。
WithCompressMiddleware 设置压缩中间件，用于处理请求和响应的压缩。当爬虫发送请求或接收响应时，该中间件可以自动处理压缩算法，解压缩请求或响应的内容。
WithDecodeMiddleware 设置解码中间件，用于处理请求和响应的解码操作。该中间件可以处理请求或响应中的编码内容。
WithDeviceMiddleware 设置开启设备模拟中间件。
WithCustomMiddleware 设置自定义中间件，允许用户定义自己的中间件组件。
WithRecordErrorMiddleware 设置错误记录中间件，请求和解析如果出错会被记录。
WithPipeline 设置Pipeline，用于处理爬取的数据并进行后续操作。
WithDumpPipeline 设置打印管道，用于打印待保存的数据。
WithFilePipeline 设置文件管道，用于处理爬取的文件数据，将文件保存到指定位置。
WithImagePipeline 设置图像管道，用于处理爬取的图像数据，将保存图像到指定位置。
WithFilterPipeline 设置过滤器管道，用于过滤爬取过的数据。
WithCsvPipeline 设置 CSV 数据处理管道，将爬取的数据保存为 CSV 格式。
WithJsonLinesPipeline 设置 JSON Lines 数据处理管道，将爬取的数据保存为 JSON Lines 格式。
WithMongoPipeline 设置 MongoDB 数据处理管道，将爬取的数据保存到 MongoDB 数据库。
WithSqlitePipeline 设置 Sqlite 数据处理管道，将爬取的数据保存到 Sqlite 数据库。
WithMysqlPipeline 设置 MySQL 数据处理管道，将爬取的数据保存到 MySQL 数据库。
WithKafkaPipeline 设置 Kafka 数据处理管道，将爬取的数据发送到 Kafka 消息队列。
WithCustomPipeline 设置自定义数据处理管道。
WithRetryMaxTimes 设置请求的最大重试次数。
WithRedirectMaxTimes 设置请求的最大跳转次数。
WithTimeout 设置请求的超时时间。
WithInterval 设置请求的间隔时间。
WithOkHttpCodes 设置正常的HTTP状态码。


  crawler选项
  #


WithLogger 设置日志。
WithMockServerRoutes 设置模拟服务Route，包括内置或自定义的。不需要配置mock_server.enable: true
WithItemDelay 设置数据保存间隔。
WithItemConcurrency 设置数据保存并行数量。
WithCDP 初始浏览器。
">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/go-crawler/docs/zh/docs/usage/options/">
  <meta property="og:site_name" content="Go Crawler">
  <meta property="og:title" content="选项">
  <meta property="og:description" content="选项 # 选项是指可以在代码中配置的条目
Spider选项 # WithName 设置唯一名称。 WithHost 设置host，用于基于host的过滤或robot.txt的支持。 WithPlatforms 设置浏览器平台。 WithBrowsers 设置浏览器。 WithFilter 设置过滤器。 WithDownloader 设置下载器。 WithExporter 设置导出器。 WithMiddleware 设置中间件。 WithStatsMiddleware 设置统计中间件，用于记录和统计爬虫的性能和运行情况。 WithDumpMiddleware 设置打印中间件，打印request或者response。 WithProxyMiddleware 设置代理中间件，用于使用代理服务器进行爬取。 WithRobotsTxtMiddleware 设置开启robots.txt支持中间件，用于遵守网站的 robots.txt 规则。 WithFilterMiddleware 设置过滤器中间件，用于过滤已处理的请求。 WithFileMiddleware 设置文件中间件，用于处理文件下载请求。 WithImageMiddleware 设置图像中间件，用于处理图像下载请求。 WithHttpMiddleware 设置 HTTP 中间件。 WithRetryMiddleware 设置重试中间件，用于在请求失败时进行自动重试。 WithUrlMiddleware 设置 URL 中间件。 WithReferrerMiddleware 设置 Referrer 中间件，用于自动设置请求的 Referrer 头。 WithCookieMiddleware 设置 Cookie 中间件，用于处理请求和响应中的 Cookie，自动在接下来的请求设置之前的 Cookie。 WithRedirectMiddleware 设置重定向中间件，用于自动处理请求的重定向，跟随重定向链接并获取最终响应。 WithChromeMiddleware 设置 Chrome 中间件，用于模拟 Chrome 浏览器。 WithHttpAuthMiddleware 设置开启HTTP认证中间件，用于处理需要认证的网站。 WithCompressMiddleware 设置压缩中间件，用于处理请求和响应的压缩。当爬虫发送请求或接收响应时，该中间件可以自动处理压缩算法，解压缩请求或响应的内容。 WithDecodeMiddleware 设置解码中间件，用于处理请求和响应的解码操作。该中间件可以处理请求或响应中的编码内容。 WithDeviceMiddleware 设置开启设备模拟中间件。 WithCustomMiddleware 设置自定义中间件，允许用户定义自己的中间件组件。 WithRecordErrorMiddleware 设置错误记录中间件，请求和解析如果出错会被记录。 WithPipeline 设置Pipeline，用于处理爬取的数据并进行后续操作。 WithDumpPipeline 设置打印管道，用于打印待保存的数据。 WithFilePipeline 设置文件管道，用于处理爬取的文件数据，将文件保存到指定位置。 WithImagePipeline 设置图像管道，用于处理爬取的图像数据，将保存图像到指定位置。 WithFilterPipeline 设置过滤器管道，用于过滤爬取过的数据。 WithCsvPipeline 设置 CSV 数据处理管道，将爬取的数据保存为 CSV 格式。 WithJsonLinesPipeline 设置 JSON Lines 数据处理管道，将爬取的数据保存为 JSON Lines 格式。 WithMongoPipeline 设置 MongoDB 数据处理管道，将爬取的数据保存到 MongoDB 数据库。 WithSqlitePipeline 设置 Sqlite 数据处理管道，将爬取的数据保存到 Sqlite 数据库。 WithMysqlPipeline 设置 MySQL 数据处理管道，将爬取的数据保存到 MySQL 数据库。 WithKafkaPipeline 设置 Kafka 数据处理管道，将爬取的数据发送到 Kafka 消息队列。 WithCustomPipeline 设置自定义数据处理管道。 WithRetryMaxTimes 设置请求的最大重试次数。 WithRedirectMaxTimes 设置请求的最大跳转次数。 WithTimeout 设置请求的超时时间。 WithInterval 设置请求的间隔时间。 WithOkHttpCodes 设置正常的HTTP状态码。 crawler选项 # WithLogger 设置日志。 WithMockServerRoutes 设置模拟服务Route，包括内置或自定义的。不需要配置mock_server.enable: true WithItemDelay 设置数据保存间隔。 WithItemConcurrency 设置数据保存并行数量。 WithCDP 初始浏览器。">
  <meta property="og:locale" content="zh">
  <meta property="og:type" content="website">
<title>选项 | Go Crawler</title>
<link rel="icon" href="/go-crawler/docs/favicon.png" >
<link rel="manifest" href="/go-crawler/docs/manifest.json">
<link rel="canonical" href="http://localhost:1313/go-crawler/docs/zh/docs/usage/options/">
  <link rel="alternate" hreflang="en" href="http://localhost:1313/go-crawler/docs/docs/usage/options/" title="Options">
<link rel="stylesheet" href="/go-crawler/docs/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css" integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin="anonymous">
  <script defer src="/go-crawler/docs/fuse.min.js"></script>
  <script defer src="/go-crawler/docs/zh.search.min.7ecfb16fa3a3cb9f912fccea1a3fe67701ac41faffe9f340d0f03ecbddb9cb31.js" integrity="sha256-fs&#43;xb6Ojy5&#43;RL8zqGj/mdwGsQfr/6fNA0PA&#43;y925yzE=" crossorigin="anonymous"></script>

  <script defer src="/go-crawler/docs/sw.min.8f5f8d39ce37f8232a7f0317a8026655f90799b045d8556ccd203097bfcc6627.js" integrity="sha256-j1&#43;NOc43&#43;CMqfwMXqAJmVfkHmbBF2FVszSAwl7/MZic=" crossorigin="anonymous"></script>
<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/go-crawler/docs/zh/docs/usage/options/index.xml" title="Go Crawler" />
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/go-crawler/docs/zh/"><span>Go Crawler</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="搜索" aria-label="搜索" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>



  



  
    
  


  


<ul class="book-languages">
  <li>
    <input type="checkbox" id="languages" class="toggle" />
    <label for="languages" class="flex justify-between">
      <a role="button" class="flex align-center">
        <img src="/go-crawler/docs/svg/translate.svg" class="book-icon" alt="Languages" />
        Chinese
      </a>
    </label>

    <ul>
      
      <li>
        <a href="/go-crawler/docs/docs/usage/options/">
          English
        </a>
      </li>
      
    </ul>
  </li>
</ul>












  



  
  <ul>
    
      
        <li>
          
  
  

  
    <span>Docs</span>
  

          
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/introduction/" class="">介绍</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/" class="">使用</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/architecture/" class="">基本架构</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/options/" class="active">选项</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/item/" class="">存储</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/tools/" class="">工具</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/middleware/" class="">中间件</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/pipeline/" class="">数据管道</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/request/" class="">请求</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/response/" class="">响应</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/signals/" class="">信号</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/proxy/" class="">代理</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/download/" class="">媒体下载</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/mock_server/" class="">模拟服务</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/configuration/" class="">配置</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/startup/" class="">启动</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/parse/" class="">基于字段标签的网页解析</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/question/" class="">问答</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/usage/example/" class="">示例代码</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/admin/" class="">Admin</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/admin/api/" class="">Api</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/go-crawler/docs/zh/docs/admin/ui/" class="">界面</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>Todo</span>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>










  
<ul>
  
  <li>
    <a href="https://github.com/lizongying/go-crawler"  target="_blank" rel="noopener">
        Github
      </a>
  </li>
  
  <li>
    <a href="https://lizongying.github.io/go-crawler/"  target="_blank" rel="noopener">
        Go Crawler Admin
      </a>
  </li>
  
</ul>






</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/go-crawler/docs/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>选项</h3>

  <label for="toc-control">
    
    <img src="/go-crawler/docs/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#选项">选项</a>
          <ul>
            <li><a href="#spider选项">Spider选项</a></li>
            <li><a href="#crawler选项">crawler选项</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h2 id="选项">
  选项
  <a class="anchor" href="#%e9%80%89%e9%a1%b9">#</a>
</h2>
<p>选项是指可以在代码中配置的条目</p>
<h3 id="spider选项">
  Spider选项
  <a class="anchor" href="#spider%e9%80%89%e9%a1%b9">#</a>
</h3>
<ul>
<li><code>WithName</code> 设置唯一名称。</li>
<li><code>WithHost</code> 设置host，用于基于host的过滤或robot.txt的支持。</li>
<li><code>WithPlatforms</code> 设置浏览器平台。</li>
<li><code>WithBrowsers</code> 设置浏览器。</li>
<li><code>WithFilter</code> 设置过滤器。</li>
<li><code>WithDownloader</code> 设置下载器。</li>
<li><code>WithExporter</code> 设置导出器。</li>
<li><code>WithMiddleware</code> 设置中间件。</li>
<li><code>WithStatsMiddleware</code> 设置统计中间件，用于记录和统计爬虫的性能和运行情况。</li>
<li><code>WithDumpMiddleware</code> 设置打印中间件，打印request或者response。</li>
<li><code>WithProxyMiddleware</code> 设置代理中间件，用于使用代理服务器进行爬取。</li>
<li><code>WithRobotsTxtMiddleware</code> 设置开启robots.txt支持中间件，用于遵守网站的 robots.txt 规则。</li>
<li><code>WithFilterMiddleware</code> 设置过滤器中间件，用于过滤已处理的请求。</li>
<li><code>WithFileMiddleware</code> 设置文件中间件，用于处理文件下载请求。</li>
<li><code>WithImageMiddleware</code> 设置图像中间件，用于处理图像下载请求。</li>
<li><code>WithHttpMiddleware</code> 设置 HTTP 中间件。</li>
<li><code>WithRetryMiddleware</code> 设置重试中间件，用于在请求失败时进行自动重试。</li>
<li><code>WithUrlMiddleware</code> 设置 URL 中间件。</li>
<li><code>WithReferrerMiddleware</code> 设置 Referrer 中间件，用于自动设置请求的 Referrer 头。</li>
<li><code>WithCookieMiddleware</code> 设置 Cookie 中间件，用于处理请求和响应中的 Cookie，自动在接下来的请求设置之前的 Cookie。</li>
<li><code>WithRedirectMiddleware</code> 设置重定向中间件，用于自动处理请求的重定向，跟随重定向链接并获取最终响应。</li>
<li><code>WithChromeMiddleware</code> 设置 Chrome 中间件，用于模拟 Chrome 浏览器。</li>
<li><code>WithHttpAuthMiddleware</code> 设置开启HTTP认证中间件，用于处理需要认证的网站。</li>
<li><code>WithCompressMiddleware</code> 设置压缩中间件，用于处理请求和响应的压缩。当爬虫发送请求或接收响应时，该中间件可以自动处理压缩算法，解压缩请求或响应的内容。</li>
<li><code>WithDecodeMiddleware</code> 设置解码中间件，用于处理请求和响应的解码操作。该中间件可以处理请求或响应中的编码内容。</li>
<li><code>WithDeviceMiddleware</code> 设置开启设备模拟中间件。</li>
<li><code>WithCustomMiddleware</code> 设置自定义中间件，允许用户定义自己的中间件组件。</li>
<li><code>WithRecordErrorMiddleware</code> 设置错误记录中间件，请求和解析如果出错会被记录。</li>
<li><code>WithPipeline</code> 设置Pipeline，用于处理爬取的数据并进行后续操作。</li>
<li><code>WithDumpPipeline</code> 设置打印管道，用于打印待保存的数据。</li>
<li><code>WithFilePipeline</code> 设置文件管道，用于处理爬取的文件数据，将文件保存到指定位置。</li>
<li><code>WithImagePipeline</code> 设置图像管道，用于处理爬取的图像数据，将保存图像到指定位置。</li>
<li><code>WithFilterPipeline</code> 设置过滤器管道，用于过滤爬取过的数据。</li>
<li><code>WithCsvPipeline</code> 设置 CSV 数据处理管道，将爬取的数据保存为 CSV 格式。</li>
<li><code>WithJsonLinesPipeline</code> 设置 JSON Lines 数据处理管道，将爬取的数据保存为 JSON Lines 格式。</li>
<li><code>WithMongoPipeline</code> 设置 MongoDB 数据处理管道，将爬取的数据保存到 MongoDB 数据库。</li>
<li><code>WithSqlitePipeline</code> 设置 Sqlite 数据处理管道，将爬取的数据保存到 Sqlite 数据库。</li>
<li><code>WithMysqlPipeline</code> 设置 MySQL 数据处理管道，将爬取的数据保存到 MySQL 数据库。</li>
<li><code>WithKafkaPipeline</code> 设置 Kafka 数据处理管道，将爬取的数据发送到 Kafka 消息队列。</li>
<li><code>WithCustomPipeline</code> 设置自定义数据处理管道。</li>
<li><code>WithRetryMaxTimes</code> 设置请求的最大重试次数。</li>
<li><code>WithRedirectMaxTimes</code> 设置请求的最大跳转次数。</li>
<li><code>WithTimeout</code> 设置请求的超时时间。</li>
<li><code>WithInterval</code> 设置请求的间隔时间。</li>
<li><code>WithOkHttpCodes</code> 设置正常的HTTP状态码。</li>
</ul>
<h3 id="crawler选项">
  crawler选项
  <a class="anchor" href="#crawler%e9%80%89%e9%a1%b9">#</a>
</h3>
<ul>
<li><code>WithLogger</code> 设置日志。</li>
<li><code>WithMockServerRoutes</code> 设置模拟服务Route，包括内置或自定义的。不需要配置<code>mock_server.enable: true</code></li>
<li><code>WithItemDelay</code> 设置数据保存间隔。</li>
<li><code>WithItemConcurrency</code> 设置数据保存并行数量。</li>
<li><code>WithCDP</code> 初始浏览器。</li>
</ul>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">


  <div><a class="flex align-center" href="https://github.com/lizongying/go-crawler/commit/7c81a24f40a46a6ade140981458f412ccd6d0c98" title='最后修改者 Li ZongYing | 十一月 27, 2023' target="_blank" rel="noopener">
      <img src="/go-crawler/docs/svg/calendar.svg" class="book-icon" alt="" />
      <span>十一月 27, 2023</span>
    </a>
  </div>



  <div>
    <a class="flex align-center" href="https://github.com/lizongying/go-crawler/edit/development/docs/content/zh/docs/usage/options/_index.md" target="_blank" rel="noopener">
      <img src="/go-crawler/docs/svg/edit.svg" class="book-icon" alt="" />
      <span>编辑本页</span>
    </a>
  </div>


</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#选项">选项</a>
          <ul>
            <li><a href="#spider选项">Spider选项</a></li>
            <li><a href="#crawler选项">crawler选项</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












